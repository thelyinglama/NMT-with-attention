{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention_is_all you need.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iMrtKMs5WRp"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOUy2mq8H_BF"
      },
      "source": [
        "import pandas as pd\n",
        "ds = pd.read_csv('/content/drive/MyDrive/Translation/eng_-french.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FfBLe68HIxIE",
        "outputId": "6905e27b-056f-46ec-82b3-da1521154cc6"
      },
      "source": [
        "ds.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English words/sentences</th>\n",
              "      <th>French words/sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Qui ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Ça alors !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  English words/sentences French words/sentences\n",
              "0                     Hi.                 Salut!\n",
              "1                    Run!                Cours !\n",
              "2                    Run!               Courez !\n",
              "3                    Who?                  Qui ?\n",
              "4                    Wow!             Ça alors !"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDN_v7RyIy43",
        "outputId": "8226f0fc-782d-4494-a017-2f13cde8260d"
      },
      "source": [
        "ds.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 175621 entries, 0 to 175620\n",
            "Data columns (total 2 columns):\n",
            " #   Column                   Non-Null Count   Dtype \n",
            "---  ------                   --------------   ----- \n",
            " 0   English words/sentences  175621 non-null  object\n",
            " 1   French words/sentences   175621 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 2.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMeAKKGaLMas"
      },
      "source": [
        "#preprocessing\n",
        "import string\n",
        "special_characters= set(string.punctuation)\n",
        "num_digits= str.maketrans('','', string.digits)\n",
        "ds['English words/sentences'] = ds['English words/sentences'].apply(lambda x: x.lower())\n",
        "ds['French words/sentences']  =ds['French words/sentences'].apply(lambda x: x.lower())\n",
        "ds['English words/sentences'] = ds['English words/sentences'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "ds['French words/sentences'] = ds['French words/sentences'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "ds['English words/sentences'] = ds['English words/sentences'].apply(lambda x: ''.join(char1 for char1 in x if char1 not in special_characters))\n",
        "ds['French words/sentences'] = ds['French words/sentences'].apply(lambda x: ''.join(char1 for char1 in x if char1 not in special_characters))\n",
        "ds['English words/sentences'] = ds['English words/sentences'].apply(lambda x: x.translate(num_digits))\n",
        "ds['French words/sentences'] = ds['French words/sentences'].apply(lambda x: x.translate(num_digits))\n",
        "ds['English words/sentences'] = ds['English words/sentences'].apply(lambda x: x.strip())\n",
        "ds['French words/sentences'] = ds['French words/sentences'].apply(lambda x: x.strip())\n",
        "ds['English words/sentences'] = ds['English words/sentences'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "ds['French words/sentences'] = ds['French words/sentences'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "ds['French words/sentences'] = ds['French words/sentences'].apply(lambda x: 'START_ '+ x + ' _END')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JgqtrcerMObT",
        "outputId": "d625e0c7-600a-439e-875e-1e28c9573a03"
      },
      "source": [
        "ds.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English words/sentences</th>\n",
              "      <th>French words/sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>START_ salut _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>run</td>\n",
              "      <td>START_ cours _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>START_ courez _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>who</td>\n",
              "      <td>START_ qui _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wow</td>\n",
              "      <td>START_ ça alors _END</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  English words/sentences French words/sentences\n",
              "0                      hi      START_ salut _END\n",
              "1                     run      START_ cours _END\n",
              "2                     run     START_ courez _END\n",
              "3                     who        START_ qui _END\n",
              "4                     wow   START_ ça alors _END"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw6DIJc_MUK-"
      },
      "source": [
        "#generating vocab\n",
        "all_source_words=set()\n",
        "for source in ds['English words/sentences']:\n",
        "    for word in source.split():\n",
        "        if word not in all_source_words:\n",
        "            all_source_words.add(word)\n",
        "\n",
        "all_target_words=set()\n",
        "for target in ds['French words/sentences']:\n",
        "    for word in target.split():\n",
        "        if word not in all_target_words:\n",
        "            all_target_words.add(word)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ior2P1NND98"
      },
      "source": [
        "source_words= sorted(list(all_source_words))\n",
        "target_words=sorted(list(all_target_words))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaFAev4xNHQD",
        "outputId": "d6f45a10-3927-42a5-bbdf-67be36cc28e2"
      },
      "source": [
        "#finding max length of sentances\n",
        "source_length_list=list()\n",
        "for l in ds['English words/sentences']:\n",
        "    source_length_list.append(len(l.split(' ')))\n",
        "max_source_length= max(source_length_list)\n",
        "print(\" Max length of the source sentence\",max_source_length)\n",
        "\n",
        "target_length_list=[]\n",
        "for l in ds['French words/sentences']:\n",
        "    target_length_list.append(len(l.split(' ')))\n",
        "max_target_length= max(target_length_list)\n",
        "print(\" Max length of the target sentence\",max_target_length)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Max length of the source sentence 44\n",
            " Max length of the target sentence 57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGupiZBmNPdw"
      },
      "source": [
        "#mapping\n",
        "source_word2idx= dict([(word, i+1) for i,word in enumerate(source_words)])\n",
        "target_word2idx=dict([(word, i+1) for i, word in enumerate(target_words)])\n",
        "\n",
        "source_idx2word= dict([(i+1, word) for word, i in  source_word2idx.items()])\n",
        "target_idx2word =dict([(i+1, word) for word, i in target_word2idx.items()])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92rZNlRSOOVF"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(ds['English words/sentences'], ds['French words/sentences'], test_size=0.1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNPtZNPJOUq1",
        "outputId": "e7f6b9bb-dafd-4dd8-f3f4-49a2311e4c50"
      },
      "source": [
        "print('Size of training data',len(x_train))\n",
        "print('Size of testing data',len(x_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training data 158058\n",
            "Size of testing data 17563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alLOuz-nOnPH"
      },
      "source": [
        "def tokenize(sentence, dict):\n",
        "  OOV_token = -99\n",
        "  tokenize_sentence = list()\n",
        "  for word in sentence.split(' '):\n",
        "    tokenize_sentence.append(dict.get(word,OOV_token))\n",
        "  #print(tokenize_sentence)\n",
        "  return tokenize_sentence"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLpO-X82u_dH"
      },
      "source": [
        "def detokenize(logvals, dict):\n",
        "  sentence = list()\n",
        "  for tokens in logvals:\n",
        "    sentence.append(dict.get(tokens,'0'))\n",
        "  #print(sentence)\n",
        "  return ' '.join(sentence)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBWfeAPQ5fl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "be59be88-c838-45ca-c0f8-a8b8925bccf4"
      },
      "source": [
        "sample = tokenize(x_train[10], source_word2idx)\n",
        "#print(x_train[1001])\n",
        "print(sample)\n",
        "detokenize(sample, source_idx2word)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[12131]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'stool'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ElKWRnG39Mv"
      },
      "source": [
        "def padding(tokens, max_len):\n",
        "  cur_length = len(tokens)\n",
        "  tokens += [0]*(max_len - cur_length)\n",
        "  return tokens"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6l11hs8WOVX",
        "outputId": "ff5c2e98-d60f-441a-afb8-d6d58f66c10f"
      },
      "source": [
        "print(padding(tokenize(x_train[1001], source_word2idx), max_source_length))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14006, 3836, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DALwK2K5Wd--"
      },
      "source": [
        "#apply padding and tokeization\n",
        "x_train_tokenized = x_train.apply(lambda x: tokenize(x, source_word2idx))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYHLJPiaalVc"
      },
      "source": [
        "x_train_padded = x_train_tokenized.apply(lambda x: padding(x, max_source_length))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVv61FmGanHC",
        "outputId": "cb8916aa-db9a-4d8e-a051-b4503cd607a7"
      },
      "source": [
        "len(x_train_padded[1000])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOIyLvukbflu"
      },
      "source": [
        "x_test_tokenized = x_test.apply(lambda x: tokenize(x, source_word2idx))\n",
        "x_test_padded = x_test_tokenized.apply(lambda x: padding(x, max_source_length))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1mAXVpMdC1Z"
      },
      "source": [
        "y_train_tokenized = y_train.apply(lambda x: tokenize(x, target_word2idx))\n",
        "y_train_padded = y_train_tokenized.apply(lambda x: padding(x, max_target_length))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTkjlTkodHaY",
        "outputId": "7850e31a-fcd1-47b1-83a1-833b4cd46c6a"
      },
      "source": [
        "y_train_padded"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58491     [1, 20154, 28009, 27656, 3730, 2, 0, 0, 0, 0, ...\n",
              "151762    [1, 13037, 21009, 9257, 27002, 3346, 21315, 14...\n",
              "171596    [1, 13037, 19260, 21380, 20164, 29373, 20803, ...\n",
              "61816     [1, 13159, 19228, 21315, 13596, 2716, 9571, 28...\n",
              "61772     [1, 13037, 9016, 21325, 7407, 2, 0, 0, 0, 0, 0...\n",
              "                                ...                        \n",
              "24509     [1, 13159, 17662, 13062, 26837, 2, 0, 0, 0, 0,...\n",
              "12573     [1, 26837, 18002, 3, 27079, 2, 0, 0, 0, 0, 0, ...\n",
              "151959    [1, 13159, 23911, 3346, 21315, 26837, 9596, 16...\n",
              "148617    [1, 26837, 24414, 21665, 9596, 4284, 28637, 23...\n",
              "132482    [1, 6978, 7494, 19344, 6181, 19533, 2, 0, 0, 0...\n",
              "Name: French words/sentences, Length: 158058, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7zYq8yAffxx"
      },
      "source": [
        "y_test_tokenized = y_test.apply(lambda x: tokenize(x, target_word2idx))\n",
        "y_test_padded = y_test_tokenized.apply(lambda x: padding(x, max_target_length))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is_c-ZdLgvC6",
        "outputId": "5e57da21-164e-436d-86ca-60ded0f8c268"
      },
      "source": [
        "y_test_padded"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66845     [1, 27002, 14232, 16735, 3, 29299, 29302, 2, 0...\n",
              "158696    [1, 27454, 1545, 21322, 3836, 6022, 14386, 198...\n",
              "101078    [1, 27656, 24819, 9997, 3378, 1063, 2, 0, 0, 0...\n",
              "16052     [1, 1588, 2004, 16706, 2, 0, 0, 0, 0, 0, 0, 0,...\n",
              "111693    [1, 3449, 19478, 15465, 13761, 5238, 2, 0, 0, ...\n",
              "                                ...                        \n",
              "67163     [1, 12076, 3, 22067, 6181, 15092, 24554, 13596...\n",
              "104964    [1, 8808, 10940, 9228, 6022, 23792, 28106, 175...\n",
              "36684     [1, 16018, 3, 9997, 27656, 5826, 28637, 23792,...\n",
              "69791     [1, 13159, 17650, 27764, 18997, 15750, 3347, 2...\n",
              "4516      [1, 23726, 26837, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0...\n",
              "Name: French words/sentences, Length: 17563, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjk31IoKktGo"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXQV5z1Qgw29"
      },
      "source": [
        "#Input encoder\n",
        "def input_encoder(vocab_size, dim, n_encoder_layers):\n",
        "  encoder = keras.Sequential()\n",
        "  encoder.add(keras.layers.Embedding(input_dim=vocab_size, output_dim=dim))\n",
        "  for _ in range(n_encoder_layers):\n",
        "    encoder.add(keras.layers.LSTM(units=dim, return_sequences=True))\n",
        "  return encoder"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB91Y-64lvpg",
        "outputId": "462d88f1-a669-4cc2-d55e-fe987d15a021"
      },
      "source": [
        "len(source_idx2word)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14409"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPeF_UVhlf2X"
      },
      "source": [
        "sample_encoder = input_encoder(len(source_word2idx),16,2)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ0xeg6ol6h1"
      },
      "source": [
        "#pre attention decoder\n",
        "def pre_attention_decoder(target_vocab_size, dim):\n",
        "  decoder = keras.Sequential()\n",
        "  decoder.add(keras.layers.Embedding(input_dim=target_vocab_size, output_dim=dim))\n",
        "  decoder.add(keras.layers.LSTM(units=dim, return_sequences=True))\n",
        "  return decoder"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oFCdnAVSx93",
        "outputId": "6cf1967f-2048-4aa3-9d73-925c3064044f"
      },
      "source": [
        "sample_decoder = pre_attention_decoder(len(target_word2idx),16)\n",
        "print(sample_decoder)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7fba7c261208>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmrhuVWaTFFI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "caa56042-f94f-41e4-b189-5bd83a5299ee"
      },
      "source": [
        "\"\"\"# attent input\n",
        "def pepare_attention_input(encoder_activations, decoder_activations, inputs):\n",
        "  keys = encoder_activations\n",
        "  values = encoder_activations\n",
        "  queries = decoder_activations\n",
        "  mask = inputs != 0\n",
        "  mask = np.reshape(mask, (mask.shape[0], 1, 1, mask.shape[1]))\n",
        "  mask = mask + np.zeros((1, 1, decoder_activations.shape[1], 1))\n",
        "  return queries, keys, values, mask\"\"\""
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'# attent input\\ndef pepare_attention_input(encoder_activations, decoder_activations, inputs):\\n  keys = encoder_activations\\n  values = encoder_activations\\n  queries = decoder_activations\\n  mask = inputs != 0\\n  mask = np.reshape(mask, (mask.shape[0], 1, 1, mask.shape[1]))\\n  mask = mask + np.zeros((1, 1, decoder_activations.shape[1], 1))\\n  return queries, keys, values, mask'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrlHM7fs21Bz",
        "outputId": "5a53d05a-90fc-453b-f0d9-ca18270f16ba"
      },
      "source": [
        "print('no timeout')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no timeout\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7_3xTxjVeDc"
      },
      "source": [
        "BUFFER_SIZE = len(x_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(x_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(source_word2idx)+1\n",
        "vocab_tar_size = len(target_word2idx)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXFqK1Xrr_a7",
        "outputId": "aacff5a8-1d0a-460e-990f-4e02af60fca6"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch, example_target_batch"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64,), dtype=string, numpy=\n",
              " array([b'did you hear all that', b'its a popular idea', b'i have tenure',\n",
              "        b'my son is now as tall as i am', b'everybody is great',\n",
              "        b'he is writing a novel', b'now its personal',\n",
              "        b'who are you waiting for',\n",
              "        b'im sure theyll be very happy together',\n",
              "        b'you didnt buy that story did you',\n",
              "        b'i have been to the airport to see him off',\n",
              "        b'dont count on them',\n",
              "        b'i think it might rain today but i could be wrong',\n",
              "        b'she must be angry with me',\n",
              "        b'he cussed me out for having lied to him',\n",
              "        b'i wouldnt do it if i were you',\n",
              "        b'it looks like the dog wants something to eat',\n",
              "        b'it was colder yesterday than today', b'tom was homeschooled',\n",
              "        b'thats a promise',\n",
              "        b'the police arrested the man who had murdered the girl',\n",
              "        b'i wont be quiet', b'shes pregnant with twins',\n",
              "        b'just as we are talking there was a loud explosion',\n",
              "        b'do you think itll fit', b'everyone stayed standing',\n",
              "        b'what would you like to do today', b'none of them look surprised',\n",
              "        b'youre better off not getting in his way',\n",
              "        b'he is probably still alive',\n",
              "        b'the companys stock price jumped yesterday', b'youre psychic',\n",
              "        b'what are your weekend plans', b'thats why im here',\n",
              "        b'do you think that you can put your idea into practice',\n",
              "        b'i was searching for something that didnt exist',\n",
              "        b'was i supposed to just ignore it',\n",
              "        b'picasso painted this picture in', b'tonight is the night',\n",
              "        b'hes coming closer', b'we were all happy',\n",
              "        b'he went into the bank', b'i cant do what im being paid to do',\n",
              "        b'the last time i went to the beach i got badly sunburned',\n",
              "        b'who invented this machine', b'i do not know exactly',\n",
              "        b'yesterday my bicycle was stolen while i was doing some shopping',\n",
              "        b'the kitchen is downstairs',\n",
              "        b'tom lives in the same apartment building as mary does',\n",
              "        b'people will laugh at you if you do something as stupid as that',\n",
              "        b'is less than', b'ive never even told my husband',\n",
              "        b'if i had my way you would all be fired',\n",
              "        b'are they friends of yours', b'im strong enough',\n",
              "        b'i told tom why i needed to do that',\n",
              "        b'it was a bitter pill to swallow',\n",
              "        b'i dont know what i want to do yet', b'who sent you here',\n",
              "        b'i want to stop this rumor before it goes any further',\n",
              "        b'tom decided not to smoke anymore',\n",
              "        b'you didnt tell me everything', b'youre sad',\n",
              "        b'hes a carbon copy of his father'], dtype=object)>,\n",
              " <tf.Tensor: shape=(64,), dtype=string, numpy=\n",
              " array([b'START_ avezvous tout entendu _END',\n",
              "        b'START_ cest une id\\xc3\\xa9e r\\xc3\\xa9pandue _END',\n",
              "        b'START_ je suis titulaire _END',\n",
              "        b'START_ mon fils est maintenant aussi grand que moi _END',\n",
              "        b'START_ tout le monde est super _END',\n",
              "        b'START_ il est en train d\\xc3\\xa9crire un roman _END',\n",
              "        b'START_ maintenant cest personnel _END',\n",
              "        b'START_ qui servezvous _END',\n",
              "        b'START_ je suis s\\xc3\\xbbre quelles seront tr\\xc3\\xa8s heureuses ensemble _END',\n",
              "        b'START_ tu nas pas gob\\xc3\\xa9 cette histoire quand m\\xc3\\xaame _END',\n",
              "        b'START_ j\\xc3\\xa9tais \\xc3\\xa0 la\\xc3\\xa9roport pour lui dire adieu _END',\n",
              "        b'START_ ne compte pas sur elles _END',\n",
              "        b'START_ je pense quil pourrait pleuvoir aujourdhui mais je peux me tromper _END',\n",
              "        b'START_ elle doit \\xc3\\xaatre en col\\xc3\\xa8re apr\\xc3\\xa8s moi _END',\n",
              "        b'START_ il ma maudit de lui avoir menti _END',\n",
              "        b'START_ je ne le ferais pas si j\\xc3\\xa9tais \\xc3\\xa0 ta place _END',\n",
              "        b'START_ il semble que le chien veuille manger quelque chose _END',\n",
              "        b'START_ il faisait plus froid hier quaujourdhui _END',\n",
              "        b'START_ tom suivait ses cours de chez lui _END',\n",
              "        b'START_ cest une promesse _END',\n",
              "        b'START_ la police a arr\\xc3\\xaat\\xc3\\xa9 lhomme qui avait tu\\xc3\\xa9 lenfant _END',\n",
              "        b'START_ je ne serai pas tranquille _END',\n",
              "        b'START_ elle est enceinte de jumeaux _END',\n",
              "        b'START_ alors m\\xc3\\xaame que nous parlions il y eut une bruyante explosion _END',\n",
              "        b'START_ pensezvous que ce sera la bonne taille _END',\n",
              "        b'START_ tout le monde est rest\\xc3\\xa9 debout _END',\n",
              "        b'START_ quaimeraistu faire aujourdhui _END',\n",
              "        b'START_ aucun deux ne para\\xc3\\xaet surpris _END',\n",
              "        b'START_ ne toppose pas \\xc3\\xa0 lui _END',\n",
              "        b'START_ il est probablement toujours en vie _END',\n",
              "        b'START_ la valeur de laction de lentreprise a bondi hier _END',\n",
              "        b'START_ tu es voyant _END',\n",
              "        b'START_ quels sont tes projets pour le weekend _END',\n",
              "        b'START_ cest pourquoi je suis ici _END',\n",
              "        b'START_ pensezvous pouvoir mettre votre id\\xc3\\xa9e en pratique _END',\n",
              "        b'START_ je cherchais quelque chose qui nexistait pas _END',\n",
              "        b'START_ \\xc3\\xa9taisje suppos\\xc3\\xa9 simplement lignorer _END',\n",
              "        b'START_ picasso a peint ce tableau en _END',\n",
              "        b'START_ cette nuit est la bonne _END',\n",
              "        b'START_ il se rapproche _END',\n",
              "        b'START_ nous \\xc3\\xa9tions toutes heureuses _END',\n",
              "        b'START_ il p\\xc3\\xa9n\\xc3\\xa9tra dans la banque _END',\n",
              "        b'START_ je narrive pas \\xc3\\xa0 faire ce pour quoi je suis pay\\xc3\\xa9 _END',\n",
              "        b'START_ la derni\\xc3\\xa8re fois que je suis all\\xc3\\xa9e \\xc3\\xa0 la plage jai \\xc3\\xa9t\\xc3\\xa9 gravement br\\xc3\\xbbl\\xc3\\xa9e par le soleil _END',\n",
              "        b'START_ qui a invent\\xc3\\xa9 cette machine _END',\n",
              "        b'START_ je ne sais pas exactement _END',\n",
              "        b'START_ hier on ma vol\\xc3\\xa9 mon v\\xc3\\xa9lo pendant que je faisais du shopping _END',\n",
              "        b'START_ la cuisine est \\xc3\\xa0 l\\xc3\\xa9tage endessous _END',\n",
              "        b'START_ tom habite dans le m\\xc3\\xaame immeuble que marie _END',\n",
              "        b'START_ les gens riront de vous si vous faites une chose aussi stupide que \\xc3\\xa7a _END',\n",
              "        b'START_ cinq est plus petit que huit _END',\n",
              "        b'START_ je ne lai jamais m\\xc3\\xaame dit \\xc3\\xa0 mon \\xc3\\xa9poux _END',\n",
              "        b'START_ si \\xc3\\xa7a ne tenait qu\\xc3\\xa0 moi vous seriez tous vir\\xc3\\xa9s _END',\n",
              "        b'START_ sontils de vos amis _END',\n",
              "        b'START_ je suis assez fort _END',\n",
              "        b'START_ jai dit \\xc3\\xa0 tom pourquoi je devais le faire _END',\n",
              "        b'START_ c\\xc3\\xa9tait une am\\xc3\\xa8re pilule \\xc3\\xa0 avaler _END',\n",
              "        b'START_ je ne sais pas encore ce que je veux faire _END',\n",
              "        b'START_ qui vous a envoy\\xc3\\xa9 ici _END',\n",
              "        b'START_ je veux mettre fin \\xc3\\xa0 cette rumeur avant quelle ne se propage plus _END',\n",
              "        b'START_ tom a d\\xc3\\xa9cid\\xc3\\xa9 de ne plus fumer _END',\n",
              "        b'START_ vous ne mavez pas tout dit _END',\n",
              "        b'START_ tu es triste _END',\n",
              "        b'START_ cest le portrait crach\\xc3\\xa9 de son p\\xc3\\xa8re _END'],\n",
              "       dtype=object)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx5fADHDZU6c"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "QvQaHYi4sf5G",
        "outputId": "0fc7063e-97d2-4848-d432-49c696e4a7e7"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, 128, 1024, 32)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-564d17a72e6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# sample input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msample_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_hidden_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msample_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_input_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Encoder output shape: (batch size, sequence length, units) {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Encoder Hidden state shape: (batch size, units) {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-d84b3d8301ef>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/embeddings.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'int32'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'int64'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharded_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mShardedVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    921\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[1;32m   1856\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: Cast string to int32 is not supported [Op:Cast]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLhiMWxK7kcN"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEsJ81wWn7oi"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07XXTNyHp0I5",
        "outputId": "5532aeb3-0d49-452f-94f5-64bddb316784"
      },
      "source": [
        "# Download the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\"\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wHqcdgFOyY9X",
        "outputId": "18e46ffc-04a0-418d-80f9-7c967676642a"
      },
      "source": [
        "path_to_file"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/spa-eng/spa.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw_dZJO6yc_6"
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhTB8CNJyhnF",
        "outputId": "361c3be4-b8c4-442e-b783-a8071ca1d855"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrCIqSBpykw9"
      },
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp0zXuf4zHpu",
        "outputId": "cd242035-52d0-47b9-f856-7f2d09e81bcc"
      },
      "source": [
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC0dlo3SzKi_"
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GJ9rnaUzNf5"
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVGbMIapzQiy"
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvYqh3tmzTP5",
        "outputId": "13957521-e74c-4c64-94f3-57c62b544d4d"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000 24000 6000 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2WN3vfdzWVb"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sip1R8kPzeou",
        "outputId": "ff55f87a-ce25-4652-b66c-34fc754c04fc"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "22 ----> por\n",
            "50 ----> favor\n",
            "32 ----> ,\n",
            "854 ----> silencio\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "453 ----> quiet\n",
            "49 ----> ,\n",
            "56 ----> please\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zhy73B1zg88"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8didWaaezsor",
        "outputId": "0ebbd4a1-7e16-413b-a999-08a0e83d78b4"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TXDsZvAPPqQ",
        "outputId": "5c2caaab-bef9-47b1-f05a-11c270a5ae48"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFcnQPdOPVmK",
        "outputId": "ba348a8f-0894-45cc-97a5-5967c3a8eae6"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EKkpO9cPa2P",
        "outputId": "8e4df7b1-a58c-4716-ae7b-afc08dc8c806"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXbzrK2HPfLq"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NomNQh8dPiw6"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze_d7g0mPlU2"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1snkVqSmPo_E",
        "outputId": "101c7364-8357-487e-a053-4a65706701a2"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.5546\n",
            "Epoch 1 Batch 100 Loss 2.1663\n",
            "Epoch 1 Batch 200 Loss 1.9327\n",
            "Epoch 1 Batch 300 Loss 1.6548\n",
            "Epoch 1 Loss 2.0154\n",
            "Time taken for 1 epoch 46.48077583312988 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4780\n",
            "Epoch 2 Batch 100 Loss 1.4342\n",
            "Epoch 2 Batch 200 Loss 1.3539\n",
            "Epoch 2 Batch 300 Loss 1.2631\n",
            "Epoch 2 Loss 1.3396\n",
            "Time taken for 1 epoch 35.07682204246521 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0029\n",
            "Epoch 3 Batch 100 Loss 0.9261\n",
            "Epoch 3 Batch 200 Loss 0.8278\n",
            "Epoch 3 Batch 300 Loss 0.7962\n",
            "Epoch 3 Loss 0.9104\n",
            "Time taken for 1 epoch 34.55885291099548 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.6427\n",
            "Epoch 4 Batch 100 Loss 0.6098\n",
            "Epoch 4 Batch 200 Loss 0.6608\n",
            "Epoch 4 Batch 300 Loss 0.5149\n",
            "Epoch 4 Loss 0.6095\n",
            "Time taken for 1 epoch 35.01180076599121 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.3444\n",
            "Epoch 5 Batch 100 Loss 0.4052\n",
            "Epoch 5 Batch 200 Loss 0.3758\n",
            "Epoch 5 Batch 300 Loss 0.4105\n",
            "Epoch 5 Loss 0.4109\n",
            "Time taken for 1 epoch 34.616313219070435 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.2272\n",
            "Epoch 6 Batch 100 Loss 0.2409\n",
            "Epoch 6 Batch 200 Loss 0.3204\n",
            "Epoch 6 Batch 300 Loss 0.2461\n",
            "Epoch 6 Loss 0.2838\n",
            "Time taken for 1 epoch 34.97474002838135 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1835\n",
            "Epoch 7 Batch 100 Loss 0.1949\n",
            "Epoch 7 Batch 200 Loss 0.1936\n",
            "Epoch 7 Batch 300 Loss 0.2003\n",
            "Epoch 7 Loss 0.2003\n",
            "Time taken for 1 epoch 34.56126618385315 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1413\n",
            "Epoch 8 Batch 100 Loss 0.1290\n",
            "Epoch 8 Batch 200 Loss 0.1501\n",
            "Epoch 8 Batch 300 Loss 0.1671\n",
            "Epoch 8 Loss 0.1499\n",
            "Time taken for 1 epoch 35.134095430374146 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1251\n",
            "Epoch 9 Batch 100 Loss 0.0885\n",
            "Epoch 9 Batch 200 Loss 0.1017\n",
            "Epoch 9 Batch 300 Loss 0.1034\n",
            "Epoch 9 Loss 0.1180\n",
            "Time taken for 1 epoch 34.81781840324402 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0887\n",
            "Epoch 10 Batch 100 Loss 0.0803\n",
            "Epoch 10 Batch 200 Loss 0.0814\n",
            "Epoch 10 Batch 300 Loss 0.1334\n",
            "Epoch 10 Loss 0.0952\n",
            "Time taken for 1 epoch 35.23683285713196 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqKvvrVRPtaC"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXJFcl_aSS0k"
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3blU8C_SVKy"
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hesBoiySX2B",
        "outputId": "bae4c103-3b94-49eb-bd91-33f3fea0c57d"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fba16a5de48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "OnuDsoxhSaGf",
        "outputId": "86900cfd-bb0f-427a-8a2d-1e51ecce9f37"
      },
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s very cold early . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nKaxIM4SdZL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}